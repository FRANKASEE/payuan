import urllib.request
from urllib.parse import urlparse
import re  # æ­£åˆ™
import os
from datetime import datetime

# æ‰§è¡Œå¼€å§‹æ—¶é—´
timestart = datetime.now()
# æŠ¥æ—¶
print(f"time: {datetime.now().strftime('%Y%m%d_%H_%M_%S')}")

# è¯»å–æ–‡æœ¬æ–¹æ³•
def read_txt_to_array(file_name):
    try:
        with open(file_name, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            lines = [line.strip() for line in lines]
            return lines
    except FileNotFoundError:
        print(f"File '{file_name}' not found.")
        return []
    except Exception as e:
        print(f"An error occurred: {e}")
        return []

# read BlackList 2024-06-17 15:02
def read_blacklist_from_txt(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()

    BlackList = [line.split(',')[1].strip() for line in lines if ',' in line]
    return BlackList

blacklist_auto = read_blacklist_from_txt('blacklist/blacklist_auto.txt')
blacklist_manual = read_blacklist_from_txt('blacklist/blacklist_manual.txt')
combined_blacklist = set(blacklist_auto + blacklist_manual)

# å®šä¹‰å¤šä¸ªå¯¹è±¡ç”¨äºå­˜å‚¨ä¸åŒå†…å®¹çš„è¡Œæ–‡æœ¬
sh_lines = []
ys_lines = []  # CCTV
ws_lines = []  # å«è§†é¢‘é“
ty_lines = []  # ä½“è‚²é¢‘é“
dy_lines = []
dsj_lines = []
gat_lines = []  # æ¸¯æ¾³å°
gj_lines = []  # å›½é™…å°
jlp_lines = []  # çºªå½•ç‰‡
other_lines = []

def process_name_string(input_str):
    parts = input_str.split(',')
    processed_parts = []
    for part in parts:
        processed_part = process_part(part)
        processed_parts.append(processed_part)
    result_str = ','.join(processed_parts)
    return result_str

def process_part(part_str):
    if "CCTV" in part_str and "://" not in part_str:
        part_str = part_str.replace("IPV6", "")  # å…ˆå‰”é™¤IPV6å­—æ ·
        part_str = part_str.replace("PLUS", "+")  # æ›¿æ¢PLUS
        part_str = part_str.replace("1080", "")  # æ›¿æ¢1080
        filtered_str = ''.join(char for char in part_str if char.isdigit() or char == 'K' or char == '+')
        if not filtered_str.strip():  # å¤„ç†ç‰¹æ®Šæƒ…å†µï¼Œå¦‚æœå‘ç°æ²¡æœ‰æ‰¾åˆ°é¢‘é“æ•°å­—è¿”å›åŸåç§°
            filtered_str = part_str.replace("CCTV", "")

        if len(filtered_str) > 2 and re.search(r'4K|8K', filtered_str):  # ç‰¹æ®Šå¤„ç†CCTVä¸­éƒ¨åˆ†4Kå’Œ8Kåç§°
            filtered_str = re.sub(r'(4K|8K).*', r'\1', filtered_str)
            if len(filtered_str) > 2:
                filtered_str = re.sub(r'(4K|8K)', r'(\1)', filtered_str)

        return "CCTV" + filtered_str

    elif "å«è§†" in part_str:
        pattern = r'å«è§†ã€Œ.*ã€'
        result_str = re.sub(pattern, 'å«è§†', part_str)
        return result_str

    return part_str

# å‡†å¤‡æ”¯æŒm3uæ ¼å¼
def get_url_file_extension(url):
    parsed_url = urlparse(url)
    path = parsed_url.path
    extension = os.path.splitext(path)[1]
    return extension

def convert_m3u_to_txt(m3u_content):
    lines = m3u_content.split('\n')
    txt_lines = []
    channel_name = ""

    for line in lines:
        if line.startswith("#EXTM3U"):
            continue
        if line.startswith("#EXTINF"):
            channel_name = line.split(',')[-1].strip()
        elif line.startswith("http") or line.startswith("rtmp") or line.startswith("p3p"):
            txt_lines.append(f"{channel_name},{line.strip()}")

    return '\n'.join(txt_lines)

def check_url_existence(data_list, url):
    urls = [item.split(',')[1] for item in data_list]
    return url not in urls

def clean_url(url):
    last_dollar_index = url.rfind('$')
    if last_dollar_index != -1:
        return url[:last_dollar_index]
    return url

def process_channel_line(line):
    if "#genre#" not in line and "," in line and "://" in line:
        channel_name = line.split(',')[0].strip()
        channel_address = clean_url(line.split(',')[1].strip())
        line = channel_name + "," + channel_address

        if channel_address not in combined_blacklist:
            if "CCTV" in channel_name and check_url_existence(ys_lines, channel_address):
                ys_lines.append(process_name_string(line.strip()))
            elif channel_name in ws_lines and check_url_existence(ws_lines, channel_address):
                ws_lines.append(process_name_string(line.strip()))
            elif channel_name in ty_lines and check_url_existence(ty_lines, channel_address):
                ty_lines.append(process_name_string(line.strip()))
            elif channel_name in dy_lines and check_url_existence(dy_lines, channel_address):
                dy_lines.append(process_name_string(line.strip()))
            elif channel_name in dsj_lines and check_url_existence(dsj_lines, channel_address):
                dsj_lines.append(process_name_string(line.strip()))
            elif channel_name in sh_lines and check_url_existence(sh_lines, channel_address):
                sh_lines.append(process_name_string(line.strip()))
            elif channel_name in gat_lines and check_url_existence(gat_lines, channel_address):
                gat_lines.append(process_name_string(line.strip()))
            elif channel_name in gj_lines and check_url_existence(gj_lines, channel_address):
                gj_lines.append(process_name_string(line.strip()))
            elif channel_name in jlp_lines and check_url_existence(jlp_lines, channel_address):
                jlp_lines.append(process_name_string(line.strip()))
            else:
                other_lines.append(line.strip())

def process_url(url):
    try:
        other_lines.append("â—†â—†â—†ã€€" + url)
        with urllib.request.urlopen(url) as response:
            data = response.read()
            text = data.decode('utf-8')

            if get_url_file_extension(url) == ".m3u" or get_url_file_extension(url) == ".m3u8":
                text = convert_m3u_to_txt(text)

            lines = text.split('\n')
            print(f"è¡Œæ•°: {len(lines)}")
            for line in lines:
                if "#genre#" not in line and "," in line and "://" in line:
                    channel_name, channel_address = line.split(',', 1)
                    if "#" not in channel_address:
                        process_channel_line(line)
                    else:
                        url_list = channel_address.split('#')
                        for channel_url in url_list:
                            newline = f'{channel_name},{channel_url}'
                            process_channel_line(newline)

            other_lines.append('\n')

    except Exception as e:
        print(f"å¤„ç†URLæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

current_directory = os.getcwd()

# è¯»å–æ–‡æœ¬
ys_dictionary = read_txt_to_array('ä¸»é¢‘é“/CCTV.txt')
sh_dictionary = read_txt_to_array('ä¸»é¢‘é“/shanghai.txt')
ws_dictionary = read_txt_to_array('ä¸»é¢‘é“/å«è§†é¢‘é“.txt')
ty_dictionary = read_txt_to_array('ä¸»é¢‘é“/ä½“è‚²é¢‘é“.txt')
dy_dictionary = read_txt_to_array('ä¸»é¢‘é“/ç”µå½±.txt')
dsj_dictionary = read_txt_to_array('ä¸»é¢‘é“/ç”µè§†å‰§.txt')
gat_dictionary = read_txt_to_array('ä¸»é¢‘é“/æ¸¯æ¾³å°.txt')
gj_dictionary = read_txt_to_array('ä¸»é¢‘é“/å›½é™…å°.txt')
jlp_dictionary = read_txt_to_array('ä¸»é¢‘é“/çºªå½•ç‰‡.txt')

# å®šä¹‰
urls = read_txt_to_array('assets/urls-daily.txt')

# è¯»å–çº é”™é¢‘é“åç§°æ–¹æ³•
def load_corrections_name(filename):
    corrections = {}
    with open(filename, 'r', encoding='utf-8') as f:
        for line in f:
            parts = line.strip().split(',')
            correct_name = parts[0]
            for name in parts[1:]:
                corrections[name] = correct_name
    return corrections

# è¯»å–çº é”™æ–‡ä»¶
corrections_name = load_corrections_name('assets/corrections_name.txt')

# çº é”™é¢‘é“åç§°
def correct_name_data(corrections, data):
    corrected_data = []
    for line in data:
        name, url = line.split(',', 1)
        if name in corrections and name != corrections[name]:
            name = corrections[name]
        corrected_data.append(f"{name},{url}")
    return corrected_data

def sort_data(order, data):
    order_dict = {name: i for i, name in enumerate(order)}
    
    def sort_key(line):
        name = line.split(',')[0]
        return order_dict.get(name, len(order))
    
    sorted_data = sorted(data, key=sort_key)
    return sorted_data

# å¤„ç†
for url in urls:
    print(f"å¤„ç†URL: {url}")
    process_url(url)

# åˆå¹¶æ‰€æœ‰å¯¹è±¡ä¸­çš„è¡Œæ–‡æœ¬ï¼ˆå»é‡ï¼Œæ’åºåæ‹¼æ¥ï¼‰
version = datetime.now().strftime("%Y%m%d-%H-%M-%S") + ",url"
all_lines = ["æ›´æ–°æ—¶é—´,#genre#"] + [version] + ['\n'] + \
            ["ğŸ†•ä¸“äº«æº1ï¸âƒ£,#genre#"] + read_txt_to_array('ä¸»é¢‘é“/â™ªä¸“äº«æºâ‘ .txt') + ['\n'] + \
            ["ğŸ†•ä¸“äº«æº2ï¸âƒ£,#genre#"] + read_txt_to_array('ä¸»é¢‘é“/â™ªä¸“äº«æºâ‘¡.txt') + ['\n'] + \
            ["ğŸ†•ä¸“äº«å¤®è§†,#genre#"] + read_txt_to_array('ä¸»é¢‘é“/â™ªä¼˜è´¨å¤®è§†.txt') + ['\n'] + \
            ["ğŸ†•ä¼˜è´¨æº,#genre#"] + read_txt_to_array('ä¸»é¢‘é“/â™ªä¼˜è´¨æº.txt') + ['\n'] + \
            ["ğŸŒå¤®è§†é¢‘é“,#genre#"] + sorted(set(ys_lines)) + ['\n'] + \
            ["ğŸ“¡å«è§†é¢‘é“,#genre#"] + sorted(set(ws_lines)) + ['\n'] + \
            ["ä¸Šæµ·é¢‘é“,#genre#"] + sorted(set(sh_lines)) + ['\n'] + \
            ["ä½“è‚²é¢‘é“,#genre#"] + sorted(set(ty_lines)) + ['\n'] + \
            ["ç”µå½±é¢‘é“,#genre#"] + sorted(set(dy_lines)) + ['\n'] + \
            ["ç”µè§†å‰§é¢‘é“,#genre#"] + sorted(set(dsj_lines)) + ['\n'] + \
            ["æ¸¯æ¾³å°,#genre#"] + sorted(set(gat_lines)) + ['\n'] + \
            ["å›½é™…å°,#genre#"] + sorted(set(gj_lines)) + ['\n'] + \
            ["çºªå½•ç‰‡,#genre#"] + sorted(set(jlp_lines)) + ['\n'] + \
            ["ç›´æ’­ä¸­å›½,#genre#"] + sorted(set(other_lines)) + ['\n']

# å°†åˆå¹¶åçš„æ–‡æœ¬å†™å…¥æ–‡ä»¶
output_file = "merged_output.txt"
others_file = "others_output.txt"
try:
    with open(output_file, 'w', encoding='utf-8') as f:
        for line in all_lines:
            f.write(line + '\n')
    print(f"åˆå¹¶åçš„æ–‡æœ¬å·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")

    with open(others_file, 'w', encoding='utf-8') as f:
        for line in other_lines:
            f.write(line + '\n')
    print(f"Otherså·²ä¿å­˜åˆ°æ–‡ä»¶: {others_file}")

except Exception as e:
    print(f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

# æ‰§è¡Œç»“æŸæ—¶é—´
timeend = datetime.now()

# è®¡ç®—æ—¶é—´å·®
elapsed_time = timeend - timestart
total_seconds = elapsed_time.total_seconds()

# è½¬æ¢ä¸ºåˆ†é’Ÿå’Œç§’
minutes = int(total_seconds // 60)
seconds = int(total_seconds % 60)
# æ ¼å¼åŒ–å¼€å§‹å’Œç»“æŸæ—¶é—´
timestart_str = timestart.strftime("%Y%m%d_%H_%M_%S")
timeend_str = timeend.strftime("%Y%m%d_%H_%M_%S")

print(f"å¼€å§‹æ—¶é—´: {timestart_str}")
print(f"ç»“æŸæ—¶é—´: {timeend_str}")
print(f"æ‰§è¡Œæ—¶é—´: {minutes} åˆ† {seconds} ç§’")

combined_blacklist_hj = len(combined_blacklist)
all_lines_hj = len(all_lines)
other_lines_hj = len(other_lines)
print(f"blacklistè¡Œæ•°: {combined_blacklist_hj} ")
print(f"merged_output.txtè¡Œæ•°: {all_lines_hj} ")
print(f"others_output.txtè¡Œæ•°: {other_lines_hj} ")
